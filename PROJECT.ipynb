{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31e986-92fd-4064-a041-11232e2d1818",
   "metadata": {},
   "source": [
    "Introduction: Water quality is essential for human health, agriculture, and the environment. However, factors like pollution, climate change, and industrial activities can impact water quality, making it difficult to predict and manage effectively. In this project, we use historical water quality data to predict future water quality levels, allowing for proactive management and ensuring safer water for communities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632f86a8-5c4a-45ff-a938-1833e4fa1cb7",
   "metadata": {},
   "source": [
    "# Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edbb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (1).csv\")\n",
    "d2 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (2).csv\")\n",
    "d3 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (3).csv\")\n",
    "d4 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (4).csv\")\n",
    "d5 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (5).csv\")\n",
    "d6 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (6).csv\")\n",
    "d7 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (7).csv\")\n",
    "d8 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (8).csv\")\n",
    "d9 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (10).csv\")\n",
    "d10 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (9).csv\")\n",
    "d11 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (11).csv\")\n",
    "d12 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (12).csv\")\n",
    "d13 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (13).csv\")\n",
    "d14 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (14).csv\")\n",
    "d15 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (15).csv\")\n",
    "d16 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (16).csv\")\n",
    "d17 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (17).csv\")\n",
    "d18 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (18).csv\")\n",
    "d19 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (19).csv\")\n",
    "d20 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (20).csv\")\n",
    "d21 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (21).csv\")\n",
    "d22 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (22).csv\")\n",
    "d23 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (23).csv\")\n",
    "d24 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (24).csv\")\n",
    "d25 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (25).csv\")\n",
    "d26 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (26).csv\")\n",
    "d27 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (27).csv\")\n",
    "d28 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (28).csv\")\n",
    "d29 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (29).csv\")\n",
    "d30 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (30).csv\")\n",
    "d31 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (31).csv\")\n",
    "d32 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (32).csv\")\n",
    "d33 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (33).csv\")\n",
    "d34 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (34).csv\")\n",
    "d35 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (35).csv\")\n",
    "d36 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (36).csv\")\n",
    "d37 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (37).csv\")\n",
    "d38 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (38).csv\")\n",
    "d39 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (39).csv\")\n",
    "d40 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (40).csv\")\n",
    "d41 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (41).csv\")\n",
    "d42 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (42).csv\")\n",
    "d43 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (43).csv\")\n",
    "d44 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (44).csv\")\n",
    "d45 = pd.read_csv(\"C:/Users/Admin/Downloads/NIWIS_DrinkingWaterQualityCompliance - Sol Plaatjie Local Municipality(NC091) - SANS 241_2015_05-Sep-2024  (45).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23,d24,d25,d26,d27,d28,d29,d30,d31,d32,d33,d34,d35,d36,d37,d38,d39,d40,d41,d42,d43,d44,d45],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49127b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e3f65-e01c-4914-b1a5-997c935e5a9a",
   "metadata": {},
   "source": [
    "The goal of this project is to predict water quality for different locations based on historical data. We will focus on predicting key water quality parameters like:\n",
    "\n",
    "Chemical Acute Health (impacts on human health),\n",
    "Chemical Aesthetic (taste, odor, and appearance),\n",
    "Chemical Chronic Health (long-term health risks),\n",
    "Chemical Disinfectant (compliance with disinfectant levels, which is important for microbial safety),\n",
    "Chemical Operational (compliance with operational factors (e.g., chlorine residual levels)).\n",
    "Microbiological Acute Health (bacterial or viral contamination).By accurately predicting these parameters, we can help municipalities and environmental agencies take action before water quality deteriorates, thus ensuring safe drinking water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b0dfd-77b5-4ead-9781-0f88d8a201c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad826c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb674b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ed0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert percentages to numerical values\n",
    "percentage_cols = ['Chemical : Acute Health', 'Chemical : Aesthetic', \n",
    "                    'Chemical : Chronic Health', 'Chemical : Disinfectant', \n",
    "                   'Chemical : Operational', 'Microbiological : Acute Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a function to clean and convert percentage strings to floats\n",
    "def convert_percentage_to_float(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove '%' and handle non-numeric values\n",
    "        if value.strip().endswith('%'):\n",
    "            try:\n",
    "                return float(value.rstrip('%')) / 100.0\n",
    "            except ValueError:\n",
    "                return np.nan  # Replace non-numeric values with NaN\n",
    "        else:\n",
    "            return np.nan  # Handle cases where '%' is missing or not valid\n",
    "    return np.nan  # Handle non-string cases\n",
    "\n",
    "# Apply the conversion function to each relevant column\n",
    "for col in percentage_cols:\n",
    "    data[col] = data[col].apply(convert_percentage_to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e296f3a-3716-4df0-a400-07d59ad73dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['From'] = pd.to_datetime(data['From'])\n",
    "data['To'] = pd.to_datetime(data['To'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af813577-2f02-4335-a22c-73f6d3874204",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19887bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings # Ignores any warning\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2970611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Chemical : Acute Health'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Chemical : Aesthetic'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Chemical : Chronic Health'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dbbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Chemical : Disinfectant'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85e07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Chemical : Operational'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ff5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# Use histplot instead of distplot\n",
    "sns.histplot(data['Microbiological : Acute Health'], bins=25, kde=True)\n",
    "\n",
    "# Adjust x-axis formatting\n",
    "plt.ticklabel_format(style='plain', axis='x', scilimits=(0,1))\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb195975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting line graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each chemical type as a line\n",
    "for column in data.columns[3:]:\n",
    "    plt.plot(data.index, data[column], marker='o', label=column)\n",
    "\n",
    "plt.xlabel('Works')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Chemical and Microbiological Data Over Time')\n",
    "plt.xticks(data.index, data['Works'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numeric = data.drop(columns=['From', 'To'])  \n",
    "\n",
    "# Set 'Works' column as index for better visualization\n",
    "data_numeric.set_index('Works', inplace=True)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data_numeric, annot=True, cmap='YlGnBu', cbar=True, fmt='.1f')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Heatmap of Chemical and Microbiological Data')\n",
    "plt.xlabel('Chemical/Microbiological Factors')\n",
    "plt.ylabel('Works')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to use 'Works' as a column\n",
    "data.reset_index(inplace=True)\n",
    "\n",
    "# Select columns for pairplot\n",
    "pairplot_data = data[['Chemical : Acute Health', 'Chemical : Aesthetic', \n",
    "                      'Chemical : Chronic Health', 'Chemical : Disinfectant', \n",
    "                      'Chemical : Operational']]\n",
    "\n",
    "# Plot pairplot\n",
    "sns.pairplot(pairplot_data)\n",
    "plt.suptitle('Pairplot of Chemical Metrics', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e653730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt data for easier plotting\n",
    "melted_data = data.melt(id_vars='Works', value_vars=['Chemical : Acute Health', \n",
    "                                                      'Chemical : Aesthetic', \n",
    "                                                      'Chemical : Chronic Health', \n",
    "                                                      'Chemical : Disinfectant', \n",
    "                                                      'Chemical : Operational'],\n",
    "                        var_name='Chemical Type', value_name='Value')\n",
    "\n",
    "# Plot boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Chemical Type', y='Value', data=melted_data)\n",
    "plt.title('Boxplot of Chemical Metrics')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afa5dc-589c-43c5-8284-2fccd408c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selecting\n",
    "#columns_to_drop = ['Works']\n",
    "#data = data.drop(columns=columns_to_drop)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f20fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selecting\n",
    "columns_to_drop = ['Works', 'From', 'To','index']\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7df89-1fb0-4858-a905-9bcdca0b87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Chemical : Acute Health', 'Chemical : Aesthetic', \n",
    "                    'Chemical : Chronic Health', 'Chemical : Disinfectant', \n",
    "                    'Chemical : Operational', 'Microbiological : Acute Health']\n",
    "\n",
    "# Calculate the averages for each numeric column\n",
    "average_row = data[numeric_columns].mean().to_frame().T\n",
    "\n",
    "# Add a label for the new row, e.g., 'Averages'\n",
    "average_row.index = ['Averages']\n",
    "\n",
    "# Append the average row to the original DataFrame\n",
    "data2 = pd.concat([data, average_row], ignore_index=False)\n",
    "# Calculate the mean for each column\n",
    "mean_values = data2[numeric_columns].mean()\n",
    "\n",
    "# Replace missing values in the numeric columns with the mean\n",
    "data2[numeric_columns] = data2[numeric_columns].fillna(mean_values)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "data2\n",
    "data2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28794af6-6f5a-4e58-91e5-93cd5f2f02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['Chemical : Acute Health', 'Chemical : Aesthetic', \n",
    "                    'Chemical : Chronic Health', 'Chemical : Disinfectant', \n",
    "                    'Chemical : Operational', 'Microbiological : Acute Health']\n",
    "\n",
    "# Add a new column with the row-wise average\n",
    "data['Row Average'] = data[numeric_columns].mean(axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44062713-55ca-425c-9f94-cd11a3b11860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classify based on the specified thresholds\n",
    "data['Classification'] = data['Row Average'].apply(\n",
    "    lambda x: 'Bad' if x < 0.95 else \n",
    "               'Poor' if 0.96 <= x <= 0.97 else \n",
    "               'Good' if 0.97 < x <= 0.992 else \n",
    "               'Excellent'\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b140df51-51ea-4c44-8646-9cb805bea921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification to numerical\n",
    "\n",
    "# Classify based on the specified thresholds\n",
    "data['Classification'] = data['Row Average'].apply(\n",
    "    lambda x: 0 if x < 0.95 else \n",
    "               1 if 0.96 <= x <= 0.97 else \n",
    "               2 if 0.97 < x <= 0.992 else \n",
    "               3\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09865396",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_counts = data['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe00e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with the mean of each column\n",
    "# Only apply to numeric columns\n",
    "numeric_columns = ['Chemical : Acute Health', 'Chemical : Aesthetic', \n",
    "                    'Chemical : Chronic Health', 'Chemical : Disinfectant', \n",
    "                    'Chemical : Operational', 'Microbiological : Acute Health','Row Average']\n",
    "\n",
    "# Calculate the mean for each column\n",
    "mean_values = data[numeric_columns].mean()\n",
    "\n",
    "# Replace missing values in the numeric columns with the mean\n",
    "data[numeric_columns] = data[numeric_columns].fillna(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3283d9-08ec-4045-948f-93f2b7fda071",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96694a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent and dependent variables\n",
    "\n",
    "X = data.drop('Classification', axis=1)\n",
    "y = data['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb32d39-3cc4-4f7d-a6b1-460b9c84653f",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882a9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model object\n",
    "model_lg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7bd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad21031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Prediction\n",
    "pred_lg = model_lg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a69f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy Score\n",
    "lg = accuracy_score(y_test, pred_lg)\n",
    "lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd485fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_lg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1a88e-0b8a-4043-8db1-572e7b7bfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from coefficients\n",
    "feature_importance_lr = np.abs(model_lg.coef_[0])\n",
    "# Sort feature importance\n",
    "sorted_indices_lr = np.argsort(feature_importance_lr)[::-1]\n",
    "\n",
    "print(\"Feature importance (Logistic Regression):\")\n",
    "for index in sorted_indices_lr:\n",
    "    print(f\"Feature {index}: {feature_importance_lr[index]}\")\n",
    "\n",
    "# Logistic Regression\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.barh(range(len(feature_importance_lr)), feature_importance_lr)\n",
    "plt.yticks(range(len(feature_importance_lr)))\n",
    "plt.title('Feature Importance (Logistic Regression)')\n",
    "plt.xlabel('Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3530c6-bd32-41fa-be22-ca9279622f29",
   "metadata": {},
   "source": [
    "# DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a297741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(max_depth=25, min_samples_split=30, min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "model_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2408a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Prediction\n",
    "pred_dt = model_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy Score\n",
    "dt = accuracy_score(y_test, pred_dt)\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be950086-3546-4047-996e-8da8ffd9cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance_dt = model_dt.feature_importances_\n",
    "# Sort feature importance\n",
    "sorted_indices_dt = np.argsort(feature_importance_dt)[::-1]\n",
    "\n",
    "print(\"Feature importance (Decision Tree):\")\n",
    "for index in sorted_indices_dt:\n",
    "    print(f\"Feature {index}: {feature_importance_dt[index]}\")\n",
    "\n",
    "# Decision Tree\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.barh(range(len(feature_importance_dt)), feature_importance_dt)\n",
    "plt.yticks(range(len(feature_importance_dt)))\n",
    "plt.title('Feature Importance (Decision Tree)')\n",
    "plt.xlabel('Importance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bd569-7df6-42a7-855a-f769c25e1e32",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25dd6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990374c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model object\n",
    "model_rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47bc0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Prediction\n",
    "pred_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7edbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy Score\n",
    "rf = accuracy_score(y_test, pred_rf)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2913b-df55-4729-9de0-8e67ff0274bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance_rf = model_rf.feature_importances_\n",
    "# Sort feature importance\n",
    "sorted_indices_rf = np.argsort(feature_importance_rf)[::-1]\n",
    "\n",
    "print(\"Feature importance (Random Forest):\")\n",
    "for index in sorted_indices_rf:\n",
    "    print(f\"Feature {index}: {feature_importance_rf[index]}\")\n",
    "\n",
    "# Random Forest\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.barh(range(len(feature_importance_rf)),feature_importance_rf )\n",
    "plt.yticks(range(len(feature_importance_rf)))\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b33291-716a-430f-aae1-afc8b26e3dec",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(min_child_weight=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61144513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3249573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Prediction\n",
    "pred_xgb = model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30958b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Accuracy Score\n",
    "xgb = accuracy_score(y_test, pred_xgb)\n",
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873710a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1f2926-b2fa-40dc-8816-4dc52fcc0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importance\n",
    "xgb_feature_importance = model_xgb.feature_importances_\n",
    "\n",
    "# Sort feature importance\n",
    "sorted_indices_xgb = np.argsort(xgb_feature_importance)[::-1]\n",
    "\n",
    "print(\"Feature importance (XGBOOST):\")\n",
    "for index in sorted_indices_xgb:\n",
    "    print(f\"Feature {index}: {xgb_feature_importance[index]}\")\n",
    "# Plot feature importance\n",
    "plt.barh(range(len(xgb_feature_importance)), xgb_feature_importance)\n",
    "plt.yticks(range(len(xgb_feature_importance)), [f\"Feature {i}\" for i in range(len(xgb_feature_importance))])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance (XGBoost)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a89ab78",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Initialize SVM with probability=True\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a49eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SVM = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1afdcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a4e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bae1d-ecfe-44da-89f1-e6579f95fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "results = permutation_importance(SVM, X_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "# Sort feature importance in descending order\n",
    "sorted_indices_svm = np.argsort(results.importances_mean)[::-1]\n",
    "\n",
    "# Print feature importance\n",
    "print(\"Feature importance (SVM):\")\n",
    "for index in sorted_indices_svm:\n",
    "    print(f\"Feature {index}: {results.importances_mean[index]}\")\n",
    "\n",
    "# Plotting\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.barh(range(len(results.importances_mean)), results.importances_mean[sorted_indices_svm], align='center')\n",
    "plt.yticks(range(len(results.importances_mean)), [f\"Feature {i}\" for i in sorted_indices_svm])\n",
    "plt.title('Feature Importance (SVM)')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e28d3b-73fb-4987-b813-372c185a7177",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa9a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=25, min_samples_split=30, min_samples_leaf=20),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, min_samples_leaf=0.11, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(min_child_weight=10),\n",
    "    \"SVM\": svm.SVC(probability=True)\n",
    "}\n",
    "\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=np.unique(y_true), \n",
    "                yticklabels=np.unique(y_true))\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# List to store training and test accuracies for each model\n",
    "model_accuracies = []\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate training and test accuracy\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Store accuracies for visualization later\n",
    "    model_accuracies.append((name, train_accuracy, test_accuracy))\n",
    "    \n",
    "    # Print accuracies and classification report\n",
    "    report = classification_report(y_test, predictions)\n",
    "    print(f\"{name} - Training Accuracy: {train_accuracy:.2f}, Test Accuracy: {test_accuracy:.2f}\\n{report}\\n\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, predictions, name)\n",
    "\n",
    "# Visualization of accuracies\n",
    "model_names = [m[0] for m in model_accuracies]\n",
    "train_acc = [m[1] for m in model_accuracies]\n",
    "test_acc = [m[2] for m in model_accuracies]\n",
    "\n",
    "x = np.arange(len(model_names))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, train_acc, width, label='Training Accuracy', color='b')\n",
    "bars2 = ax.bar(x + width/2, test_acc, width, label='Test Accuracy', color='r')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Training and Test Accuracy of Different Models')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.legend()\n",
    "\n",
    "# Adding accuracy values on top of bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}', \n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d201fc-823b-4935-b6e9-37a7b8e6b2a7",
   "metadata": {},
   "source": [
    "# Future values for average water quality based on parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a0463",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Row Average'], label='Row Average')\n",
    "plt.title('Row Average Time Series')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Row Average')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e780092-e0a1-4c6e-a046-1d0756a665a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7383b222-b34e-4ed3-8a97-775b174bb073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data['Row Average'].dropna(), lags=20)\n",
    "plt.title('ACF Plot')\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(data['Row Average'].dropna(), lags=20)\n",
    "plt.title('PACF Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d56ea6-522e-467b-a278-2ec7c4c91f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(data['Row Average'], order=(1, 1, 1))\n",
    "fitted_model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f3154-6963-486c-b728-6d7c3ed8ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba314a8-bcb6-42e3-a7ef-800b1cc35327",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = fitted_model.forecast(steps=15)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db46dadc-1294-4cce-9b83-33348f26e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Row Average'], label='Historical Data')\n",
    "plt.plot(range(len(data), len(data) + len(forecast)), forecast, label='Forecast', color='red')\n",
    "plt.title('ARIMA Forecast')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Row Average')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273b1b3c-23ec-442d-8b96-49d6c15dd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cb815-25d0-45dd-b1be-5b5cf10a7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Row Average' is the column you're using.\n",
    "\n",
    "# Plotting the Row Average time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Row Average'], label='Row Average')\n",
    "plt.title('Row Average Time Series')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Row Average')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ACF and PACF plots\n",
    "plot_acf(data['Row Average'].dropna(), lags=20)\n",
    "plt.title('ACF Plot')\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(data['Row Average'].dropna(), lags=20)\n",
    "plt.title('PACF Plot')\n",
    "plt.show()\n",
    "\n",
    "# Fit the ARIMA model\n",
    "model = ARIMA(data['Row Average'], order=(1, 1, 1))\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(fitted_model.summary())\n",
    "\n",
    "# Forecast the next 5 steps\n",
    "forecast = fitted_model.forecast(steps=5)\n",
    "print(forecast)\n",
    "\n",
    "# Define y_test correctly (the last 5 observations from the data)\n",
    "y_test = data['Row Average'].iloc[-5:].values\n",
    "\n",
    "# Calculate and print error metrics\n",
    "mse = mean_squared_error(y_test, forecast)\n",
    "print('MSE: ' + str(mse))\n",
    "mae = mean_absolute_error(y_test, forecast)\n",
    "print('MAE: ' + str(mae))\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE: ' + str(rmse))\n",
    "mape = np.mean(np.abs(forecast - y_test) / np.abs(y_test)) * 100  # MAPE as a percentage\n",
    "print('MAPE: ' + str(mape))\n",
    "\n",
    "# Plotting historical data with forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Row Average'], label='Historical Data')\n",
    "plt.plot(range(len(data), len(data) + len(forecast)), forecast, label='Forecast', color='red')\n",
    "plt.title('ARIMA Forecast')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Row Average')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf5b981-a30f-4188-a2ff-6864a54178fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA coefficients\n",
    "# Feature Importance\n",
    "arima_coefficients = fitted_model.params\n",
    "print(\"ARIMA Coefficients:\")\n",
    "print(arima_coefficients)\n",
    "\n",
    "# Plotting ARIMA coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "arima_coefficients.plot(kind='bar')\n",
    "plt.title('ARIMA Coefficients')\n",
    "plt.xlabel('Parameters')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ace365-87bf-43cc-9789-064fa202e3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "477f4e3d-7db9-4768-9a8d-4bceba29b04a",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cb16e-fc3d-4e8d-8f2b-59f9403a9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "values = data['Row Average'].values\n",
    "\n",
    "# Reshape and scale the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(values.reshape(-1, 1))\n",
    "\n",
    "# Function to create datasets\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - time_step - 1):\n",
    "        a = data[i:(i + time_step), 0]\n",
    "        X.append(a)\n",
    "        y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set the time step\n",
    "time_step = 10\n",
    "X, y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a134ae-593f-4067-afc1-6aae8a5c31bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
    "model.add(Dropout(0.2))  # Prevent overfitting\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c55511-d1b4-4026-bcd5-ddd8c8328866",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52621171-46ec-4f9f-9955-06bf2f39d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for prediction\n",
    "last_values = scaled_data[-time_step:].reshape(1, time_step, 1)\n",
    "predicted_scaled = model.predict(last_values)\n",
    "\n",
    "# Inverse transform the predicted value\n",
    "predicted_value = scaler.inverse_transform(predicted_scaled)\n",
    "\n",
    "print(\"Predicted Value:\", predicted_value[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356ea61-f8a9-4dd2-bbd6-ac8ea5bbeecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_steps = 15\n",
    "predictions = []\n",
    "\n",
    "# Generate future predictions\n",
    "for _ in range(future_steps):\n",
    "    predicted_scaled = model.predict(last_values)\n",
    "    predicted_value = scaler.inverse_transform(predicted_scaled)\n",
    "    predictions.append(predicted_value[0][0])\n",
    "\n",
    "    # Update the input for the next prediction\n",
    "    last_values = np.append(last_values[:, 1:, :], predicted_scaled.reshape(1, 1, 1), axis=1)\n",
    "\n",
    "print(\"Future Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e1ad7-9d0c-4c51-a658-c5465b1590bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate performance metrics\n",
    "y_true = values[-future_steps:]  # Last known values for comparison\n",
    "y_pred = predictions\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate MAPE\n",
    "# Avoid division by zero by adding a small constant to the true values\n",
    "mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAPE: {mape}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3e23a-4712-4024-9831-a690eaa09e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Row Average'], label='Historical Data')\n",
    "\n",
    "# Create a range for future predictions\n",
    "future_index = np.arange(len(data), len(data) + future_steps)\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(future_index, predictions, label='Predictions', color='red')\n",
    "plt.title('LSTM Forecasting')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Row Average')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d062b6f-ccd8-4a5d-9c75-5ef9cbb28094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance(model, X, y, time_step):\n",
    "    baseline_mse = mean_squared_error(y, model.predict(X))\n",
    "    importances = []\n",
    "    \n",
    "    for i in range(X.shape[1]):  # Loop over each feature\n",
    "        # Create a copy of the input\n",
    "        X_permuted = X.copy()\n",
    "        \n",
    "        # Shuffle the specific feature\n",
    "        np.random.shuffle(X_permuted[:, i])\n",
    "        \n",
    "        # Evaluate the model on the permuted data\n",
    "        mse = mean_squared_error(y, model.predict(X_permuted))\n",
    "        importances.append(baseline_mse - mse)  # Calculate importance\n",
    "    \n",
    "    return importances\n",
    "\n",
    "# Calculate feature importance\n",
    "feature_importance = permutation_importance(model, X, y, time_step)\n",
    "print(\"LSTM Feature Importances:\", feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67715d38-1c2b-453c-a71f-176eed5cc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), feature_importance)\n",
    "plt.title('LSTM Feature Importance (Permutation)')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2ac58-af69-4063-9af0-67893c494a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd771109-6668-41d5-877e-a8fc92f4843a",
   "metadata": {},
   "source": [
    "# Future values for on each parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4a09c-c384-4c55-b0eb-f99191aa475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of future periods you want to predict\n",
    "num_future_periods = 15\n",
    "\n",
    "# Prepare an index for future predictions\n",
    "future_index = [f'Future_{i+1}' for i in range(num_future_periods)]\n",
    "\n",
    "# Initialize a DataFrame to hold the predictions\n",
    "predicted_averages = pd.DataFrame(index=future_index)\n",
    "\n",
    "# Fit model and predict future values\n",
    "for col in data2.columns:\n",
    "    # Create time variable\n",
    "    time_index = np.arange(len(data2)).reshape(-1, 1)  # Reshape for sklearn\n",
    "    model = LinearRegression()\n",
    "    model.fit(time_index, data2[col].values)\n",
    "    \n",
    "    # Prepare future time points\n",
    "    future_time = np.array([[len(data2) + i] for i in range(1, num_future_periods + 1)])\n",
    "    future_values = model.predict(future_time)\n",
    "    \n",
    "    # Store predictions in the new DataFrame\n",
    "    predicted_averages[col] = future_values\n",
    "\n",
    "# Display predicted averages\n",
    "print(predicted_averages)\n",
    "\n",
    "# Now, you can append the predictions to the original DataFrame\n",
    "final_data = pd.concat([data2, predicted_averages])\n",
    "final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333eb033-b5d7-496f-98fc-b76ba5e2cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define the number of future periods you want to predict\n",
    "num_future_periods = 15\n",
    "\n",
    "# Prepare an index for future predictions\n",
    "future_index = [f'Future_{i+1}' for i in range(num_future_periods)]\n",
    "\n",
    "# Initialize a DataFrame to hold the predictions\n",
    "predicted_averages = pd.DataFrame(index=future_index)\n",
    "\n",
    "# Initialize a DataFrame for storing evaluation metrics\n",
    "metrics = pd.DataFrame(columns=['MAE', 'MSE', 'RMSE', 'R2'])\n",
    "\n",
    "# Fit model and predict future values\n",
    "for col in data2.columns:\n",
    "    # Create time variable (using index as time)\n",
    "    time_index = np.arange(len(data2)).reshape(-1, 1)  # Reshape for sklearn\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
    "    train_size = int(0.8 * len(data2))\n",
    "    train_data = data2[col].values[:train_size]\n",
    "    test_data = data2[col].values[train_size:]\n",
    "    train_time = time_index[:train_size]\n",
    "    test_time = time_index[train_size:]\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(train_time, train_data)\n",
    "    \n",
    "    # Predict the test data\n",
    "    test_predictions = model.predict(test_time)\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    mae = mean_absolute_error(test_data, test_predictions)\n",
    "    mse = mean_squared_error(test_data, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(test_data, test_predictions)\n",
    "    \n",
    "    # Store the evaluation metrics\n",
    "    metrics.loc[col] = [mae, mse, rmse, r2]\n",
    "    \n",
    "    # Prepare future time points\n",
    "    future_time = np.array([[len(data2) + i] for i in range(1, num_future_periods + 1)])\n",
    "    future_values = model.predict(future_time)\n",
    "    \n",
    "    # Store predictions in the new DataFrame\n",
    "    predicted_averages[col] = future_values\n",
    "\n",
    "# Display predicted averages\n",
    "print(\"Predicted Future Values:\")\n",
    "print(predicted_averages)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(metrics)\n",
    "\n",
    "# Now, you can append the predictions to the original DataFrame\n",
    "final_data = pd.concat([data2, predicted_averages])\n",
    "print(\"\\nFinal Data (Original + Predictions):\")\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7315a702-515b-43eb-ad01-1a429819cb25",
   "metadata": {},
   "source": [
    "With these models we can see how the future water quality of this location will be like, with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcfd04-322d-4f09-bf89-1a4f4e925dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8e9c5-e301-4a8b-9f3f-886ed30551a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Display the best model\n",
    "best_model_widget = widgets.Output()\n",
    "with best_model_widget:\n",
    "    display(best_model)\n",
    "\n",
    "display(best_model_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1cc31-54bf-48a1-8ae8-9a748c53da2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
